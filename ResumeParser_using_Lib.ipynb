{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResumeParser using Lib.ipynb",
      "provenance": [],
      "mount_file_id": "1wt9sym6GknuHb2B1Gko6UQii_uhC8lKe",
      "authorship_tag": "ABX9TyMOmPNUvObiv+4/e0CxoEbZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepankar-pathak1/Resume-Analyzer/blob/main/ResumeParser_using_Lib.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRVd293oGfAd",
        "outputId": "20bcbcac-5efb-4b6f-dca8-33324555c4b2"
      },
      "source": [
        "!pip install spacy==2.2.2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting spacy==2.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/05/e82c888a36f24608664b56abe737f4428410d370791f6112fb3e9b4a4a81/spacy-2.2.2-cp36-cp36m-manylinux1_x86_64.whl (10.3MB)\n",
            "\u001b[K     |████████████████████████████████| 10.3MB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.2) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.2) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.2) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.2) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.2) (1.1.3)\n",
            "Collecting thinc<7.4.0,>=7.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/59/6bb553bc9a5f072d3cd479fc939fea0f6f682892f1f5cff98de5c9b615bb/thinc-7.3.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 44.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.2) (51.3.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.2) (3.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.2) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.2) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.2) (0.8.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from spacy==2.2.2) (1.0.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.2) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.2) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.2.2) (1.24.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<7.4.0,>=7.3.0->spacy==2.2.2) (4.41.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy==2.2.2) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy==2.2.2) (3.7.4.3)\n",
            "Installing collected packages: thinc, spacy\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed spacy-2.2.2 thinc-7.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmS6QqSCGvtZ",
        "outputId": "c1a08b36-f2ee-4b88-bfc4-f23787bfd382"
      },
      "source": [
        "# https://www.youtube.com/watch?v=wRA4zM5jtOU&ab_channel=VermaAnalyst\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "# from resume_parser import resumeparse\r\n",
        "from pyresparser import ResumeParser\r\n",
        "import os\r\n",
        "import spacy\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMhlTvoGHtIc"
      },
      "source": [
        "# !pip install resume-parser"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5yMBwR5HRNF"
      },
      "source": [
        "# !pip uninstall pdfminer-six 20201018"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqCSEMClIgv4"
      },
      "source": [
        "# !pip install pdfminer.six==20200517"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9es7oLAVIlDf"
      },
      "source": [
        "# !pip install pyresparser"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VK4WDE_nI95O"
      },
      "source": [
        "# !pip uninstall urllib3 1.26.3"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yr0k2NjJJO6p"
      },
      "source": [
        "# !pip uninstall urllib3==1.21.1"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqivhmmJJu5j"
      },
      "source": [
        "# !pip uninstall urllib3==1.25.2"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-NuVyf_KVMw"
      },
      "source": [
        "# pip install urllib3==1.25.3"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28RGRrBvKkFO"
      },
      "source": [
        "# !pip uninstall folium 0.8.3"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1vgeFDuKpdE"
      },
      "source": [
        "# !pip install folium==0.2.1"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euGEqVkVKu-z"
      },
      "source": [
        "# !pip uninstall pytz 2020.5"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBxBxxM5LO82"
      },
      "source": [
        "# !pip uninstall pytz==2014.10"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nZDM8OhLVUy"
      },
      "source": [
        "# !pip install pytz==2019.2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3hxyIm8N88L"
      },
      "source": [
        "# !pip uninstall spacy 2.3.5"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTdD-bHJOY-1"
      },
      "source": [
        "# !pip install spacy==2.2.2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2RkxfJ0LrLw"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zdp5uaxMMXfU"
      },
      "source": [
        "data = ResumeParser('/content/Alice Clark CV.pdf').get_extracted_data()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X87ErYl7Mdfc",
        "outputId": "675bc6c6-8db9-473c-bd31-38826d7565e4"
      },
      "source": [
        "print(data)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'name': 'snow flake', 'email': None, 'mobile_number': None, 'skills': ['Sql', 'Email', 'Design', 'Cloud', 'Website', 'Communication', 'Writing', 'Windows', 'Technical', 'Warehouse', 'Analytical', 'Big data', 'Lifecycle', 'Data analysis', 'Analytics', 'Business intelligence', 'Database', 'Ai', 'Analysis'], 'college_name': None, 'degree': None, 'designation': ['Software Engineer'], 'experience': ['Software Engineer', 'Microsoft – Bangalore, Karnataka', 'January 2000 to Present', '1. Microsoft Rewards Live dashboards:', 'Description: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping', 'online. Microsoft Rewards members can earn points when searching with Bing, browsing with', 'Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft', 'Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft', 'rewards website. Rewards live dashboards gives a live picture of usage world-wide and by', 'markets like US, Canada, Australia, new user registration count, top/bottom performing rewards', 'offers, orders stats and weekly trends of user activities, orders and new user registrations. the', 'PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes.', 'Technology/Tools used', 'Indian Institute of Technology – Mumbai'], 'company_names': ['Microsoft'], 'no_of_pages': 2, 'total_experience': 21.08}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AZNl6TXMqb4",
        "outputId": "b2bd2af7-da72-4869-8beb-a8638b136b41"
      },
      "source": [
        "print(type(data))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w8E3Dm6M1yx",
        "outputId": "c557ed7e-ef83-4d3b-a459-e982a3b01f5d"
      },
      "source": [
        "for key,values in data.items():\r\n",
        "  print(f\"{key} --> {values}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name --> snow flake\n",
            "email --> None\n",
            "mobile_number --> None\n",
            "skills --> ['Sql', 'Email', 'Design', 'Cloud', 'Website', 'Communication', 'Writing', 'Windows', 'Technical', 'Warehouse', 'Analytical', 'Big data', 'Lifecycle', 'Data analysis', 'Analytics', 'Business intelligence', 'Database', 'Ai', 'Analysis']\n",
            "college_name --> None\n",
            "degree --> None\n",
            "designation --> ['Software Engineer']\n",
            "experience --> ['Software Engineer', 'Microsoft – Bangalore, Karnataka', 'January 2000 to Present', '1. Microsoft Rewards Live dashboards:', 'Description: - Microsoft rewards is loyalty program that rewards Users for browsing and shopping', 'online. Microsoft Rewards members can earn points when searching with Bing, browsing with', 'Microsoft Edge and making purchases at the Xbox Store, the Windows Store and the Microsoft', 'Store. Plus, user can pick up bonus points for taking daily quizzes and tours on the Microsoft', 'rewards website. Rewards live dashboards gives a live picture of usage world-wide and by', 'markets like US, Canada, Australia, new user registration count, top/bottom performing rewards', 'offers, orders stats and weekly trends of user activities, orders and new user registrations. the', 'PBI tiles gets refreshed in different frequencies starting from 5 seconds to 30 minutes.', 'Technology/Tools used', 'Indian Institute of Technology – Mumbai']\n",
            "company_names --> ['Microsoft']\n",
            "no_of_pages --> 2\n",
            "total_experience --> 21.08\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4Z8OV1dNYOA"
      },
      "source": [
        "data_1 = ResumeParser('/content/Deepankar data-.pdf').get_extracted_data()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPDBL3xwNzwO",
        "outputId": "3c1999bf-30f5-4ef0-cea5-04172e7b05da"
      },
      "source": [
        "for i,j in data_1.items():\r\n",
        "    print(f\"{i} --> {j}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name --> Deepankar pathak\n",
            "email --> pathakdeepankar989@gmail.com\n",
            "mobile_number --> 9166759124\n",
            "skills --> ['Analysis', 'Seaborn', 'Sql', 'Teaching', 'English', 'Pandas', 'Matplotlib', 'Computer science', 'Excel', 'Numpy', 'Nltk', 'Microsoft excel', 'Ibm', 'Machine learning', 'Programming', 'Tableau', 'Github', 'Engineering', 'Python']\n",
            "college_name --> None\n",
            "degree --> ['Bachelor of Technology, Computer science Engineering  \\n \\nCertifications \\n \\n\\n• \\n\\nIBM: - Python for Data Science and A.I.']\n",
            "designation --> None\n",
            "experience --> None\n",
            "company_names --> None\n",
            "no_of_pages --> 1\n",
            "total_experience --> 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXxZYI3dQO0r",
        "outputId": "b094ed14-1138-435a-c719-02219f5fa738"
      },
      "source": [
        "for i,j in data_1.items():\r\n",
        "    if i == 'skills':\r\n",
        "        for m in j:\r\n",
        "            print(m)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analysis\n",
            "Seaborn\n",
            "Sql\n",
            "Teaching\n",
            "English\n",
            "Pandas\n",
            "Matplotlib\n",
            "Computer science\n",
            "Excel\n",
            "Numpy\n",
            "Nltk\n",
            "Microsoft excel\n",
            "Ibm\n",
            "Machine learning\n",
            "Programming\n",
            "Tableau\n",
            "Github\n",
            "Engineering\n",
            "Python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAB9rkpzPicC"
      },
      "source": [
        "data_2 = ResumeParser('/content/Smith Resume.pdf').get_extracted_data()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68WdwpOnP_pe",
        "outputId": "3aebfbc4-762b-46b2-8574-ac371fc4dd38"
      },
      "source": [
        "for m,n in data_2.items():\r\n",
        "    print(f\"{m}--{n}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name--Michael Smith\n",
            "email--None\n",
            "mobile_number--None\n",
            "skills--['Design', 'Writing', 'Reporting', 'Transactions', 'Administration', 'Etl', 'Analysis', 'Windows', 'Technical', 'Modeling', 'Sql server', 'Lifecycle', 'Schedule', 'Analytics', 'Js', 'Api', 'Email', 'Cloud', 'Communication', 'Routing', 'Access', 'Warehouse', 'Big data', '.net', 'Reports', 'Sql', 'C#', 'Website', 'C', 'Process', 'Sap', 'Analytical', 'Data analytics', 'Data analysis', 'Metrics', 'Database']\n",
            "college_name--None\n",
            "degree--None\n",
            "designation--None\n",
            "experience--['writing andoptimizing SQL code and Stored Procedures, creating functions, views,', 'triggers and indexes.', 'Cloud  platform:  Worked  on  Microsoft  Azure  cloud  services  like  Document  DB,  SQL', 'Azure, StreamAnalytics, Event hub,  Power BI, Web Job, Web App, Power BI, Azure', 'data lake analytics(U-SQL).', 'Big Data: Worked Azure data lake store/analytics for big data processing and Azure', 'data factoryto schedule U-SQL jobs. Designed and developed end to end  big data', 'solution for data insights.', 'Willing to relocate: Anywhere', 'WORK EXPERIENCESoftware Engineer', 'Microsoft - Manchester, UK.', 'December 2015 to Present', '1. Microsoft Rewards Live dashboards:', 'Description:  -  Microsoft  rewards  is  loyalty  program  that  rewards  Users  for', 'browsing  and  shopping  online.  Microsoft  Rewards  members  can  earn  points  when', 'searching  with  Bing,  browsing  with  Microsoft  Edge  and  making  purchases  at  the', 'Xbox  Store,  the  Windows  Store  and  the  Microsoft  Store.  Plus,  user  can  pick  up', 'bonus points for taking daily quizzes and tours on the Microsoft rewards website.', 'Rewards live dashboards gives a live picture of usage world-wide and by markets', 'like  US,  Canada,  Australia,  new  user  registration  count,  top/bottom  performing', 'rewards offers, orders stats and weekly trends of user activities, orders and new', 'user registrations. the PBI tiles gets refreshed in different frequencies starting', 'from 5 seconds to 30 minutes.', 'Technology/Tools used', 'Event hub, stream analytics and Power BI.', 'Responsibilities', 'Created stream analytics jobs to process event hub data', 'Created Power BI live dashboard to show live usage traffic, weekly trends, cards,', 'charts to showtop/bottom 10 offers and usage metrics.', '2. Microsoft Rewards Data Insights:', 'Description:  -  Microsoft  rewards  is  loyalty  program  that  rewards  Users  for', 'browsing  and  shopping  online.  Microsoft  Rewards  members  can  earn  points  when', 'searching  with  Bing,  browsing  with  Microsoft  Edge  and  making  purchases  at  the', 'Xbox  Store,  the  Windows  Store  and  the  Microsoft  Store.  Plus,  user  can  pick  up', 'bonus points for taking daily quizzes and tours on the Microsoft rewards website.', 'Rewards  data  insights  is  data  analytics  and  reporting  platform,  processes  20', 'million users daily activities and redemption across different markets like US,', 'Canada, Australia.', 'Technology/Tools used', 'Cosmos (Microsoft big-data platform), c#, X-flow job monitoring, Power BI.', 'Responsibilities', 'Created big data scripts in cosmos', 'C# data extractors, processors and reducers for data transformation', 'Power BI dashboards', '3. End to end tracking Tool:', 'Description:  -  This  is  real-time  Tracking  tool  to  track  different  business', 'transactions  like  order,  order  response,  functional  acknowledgement,  invoice', 'flowing inside ICOE. It gives flexibility to customers to track their transactions', 'and appropriate error information in-case of any failure. Based on resource based', 'access control the tool gives flexibility to end user to perform different actions', 'like  view  transactions,  search  based  on  different  filter  criteria  and  view  and', 'download  actual  message  payload.  End  to  end  tracking  tool  stitches  all  the', 'business transaction like order to cash flow and connects different hops inside', 'ICOE like gateway, routing server, Processing server. It also connects different', 'systems like ICOE, partner end point and SAP.', 'Technology/Tools used', 'Azure Document db, Azure web job and Web APP, RBAC, Angular JS.', 'Responsibilities', 'Document dB stored procedures.', 'Web job to process event hub data and populate Document db• Web App API.', 'Stream analytics job to transform data', 'Power BI reports', '4. Biztrack Tracking Tool:', 'Description:  -  This  is  real-time  Tracking  tool  to  track  different  business', 'transactions  like  order,  order  response,  functional  acknowledgement,  invoice', 'flowing inside ICOE. It gives flexibility to customers to track their transactions', 'and appropriate error information in-case of any failure. Based on resource based', 'access control the tool gives flexibility to end user to perform different actions', 'like  view  transactions,  search  based  on  different  filter  criteria  and  view  and', 'download actual message payload.', 'Technology/Tools used', 'SQL server 2014, SSIS, .net API, Angular JS.', 'Responsibilities', 'ETL solution to transform business transactions data stored in Biztalk tables.', 'SQL azure tables, stored procedures, User defined functions.', 'Performance tuning.', 'Web API enhancements.']\n",
            "company_names--['Microsoft']\n",
            "no_of_pages--3\n",
            "total_experience--5.17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl87AC3nQHz7"
      },
      "source": [
        "data_5 = ResumeParser(r'/content/CV_HeZhang.pdf').get_extracted_data()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZiO_SJrbg4m",
        "outputId": "59e01247-80da-49b8-d7b6-29fd21c2980d"
      },
      "source": [
        "print(type(data_5))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prMhzKdRbk4P",
        "outputId": "e7d7bb87-e297-4d63-f1a1-2f0a94ce765f"
      },
      "source": [
        "for i, j in data_5.items():\r\n",
        "    print(f\"{i} -- > {j}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name -- > Data Scientist\n",
            "email -- > klarke4001@gmail.com\n",
            "mobile_number -- > 358-5051888\n",
            "skills -- > ['English', 'Writing', 'International', 'Segmentation', 'Updates', 'Presentation', 'Travel', 'Transactions', 'Analysis', 'C++', 'Technical', 'Matrix', 'Machine learning', 'Analytics', 'Research', 'Python', 'Algorithms', 'Email', 'Communication', 'Supervisor', 'Matlab', 'Marketing', 'System', 'Video', 'Mobile', 'Datasets', 'Javascript', 'Reports', 'Mining', 'Sql', 'Perl', 'C', 'Computer science', 'Content', 'Analytical', 'Data analytics', 'Programming', 'Engineering', 'Pattern']\n",
            "college_name -- > None\n",
            "degree -- > None\n",
            "designation -- > None\n",
            "experience -- > ['Finnish:            Basic. I received full scores in 4 consecutive Aalto University Finnish Exams', 'China HR Ministry.', '2006-2007.', 'Chinese:           Native.', 'Programming:  Matlab, Python, SQL, Perl, JavaScript, C / C++, LaTeX (for document writing)', 'POSITIONS OF TRUST', '2014                  Programme Committee Member in 2014 International Conference on Artiﬁcial', 'Neural Networks (ICANN), Hamburg, Germany.', '2014                  Reviewer for Scientiﬁc Journals, e.g., IEEE Transactions on Neural Networks', 'and Learning Systems, Information Sciences, Neurocomputing, Journal of', 'Optical Engineering.', '2013                  Membership in European Neural Networks Society (ENNS)', 'REFEREES', 'Professor Erkki Oja, PhD Supervisor                                                              Email: erkki.oja@aalto.ﬁ', 'Department of Computer Science, Aalto University School of Science, Espoo, Finland', 'Professor Timo Honkela, Research Collaborator                                 Email: timo.honkela@helsinki.ﬁ', 'Department of Language, University of Helsinki, Helsinki, Finland', 'Senior Scientist Jorma Laaksonen, (former) PhD Instructor              Email: jorma.laaksonen@aalto.ﬁ', 'Department of Computer Science, Aalto University School of Science, Espoo, Finland', 'CV: He Zhang, +358-50-5188888, klarke4001@gmail.com                  Page 2/3', 'PUBLICATION LIST', 'Journal Articles', '1. He Zhang, Zhirong Yang, and Erkki Oja. Improving Cluster Analysis By Co-initialisations. Pattern', 'Recognition Letters, 45: 71-77, 2014.', '2. He Zhang, Zhirong Yang, and Erkki Oja. Adaptive Multiplicative Updates for Quadratic Nonnegative Matrix', 'Factorisation. Neurocomputing, 134: 206-213, 2014.', '3. He Zhang, Mehmet Gönen, Zhirong Yang, and Erkki Oja. Understanding Emotional Impact of Images', 'Using Bayesian Multiple Kernel Learning. Neurocomputing, 165: 3-13, 2015.', 'Conference Papers', '4. He Zhang, Mehmet Gönen, Zhirong Yang, and Erkki Oja. Predicting Emotional States of Images Using', 'Bayesian Multiple Kernel Learning. In Proceedings of the 20th International Conference on Neural', 'Information Processing (ICONIP), Daegu, South Korea, 2013. Oral presentation.', '5. He Zhang, Zhirong Yang, Mehmet Gönen, Markus Koskela, Jorma Laaksonen, Timo Honkela, and Erkki', 'Oja. Affective Abstract Image Classiﬁcation and Retrieval Using Multiple Kernel Learning. ICONIP 2013,', 'Daegu, South Korea, 2013. Oral presentation.', '6. He Zhang, Zhirong Yang, and Erkki Oja. Adaptive Multiplicative Updates for Projective Nonnegative Matrix', 'Factorisation. ICONIP 2012, Doha, Qatar, 2012. Oral presentation.', '7. Zhirong Yang, He Zhang, and Erkki Oja. Online Projective Nonnegative Matrix Factorisation for Large', 'Datasets. ICONIP 2012, Doha, Qatar, 2012. Oral presentation.', '8. He Zhang, Tele Hao, Zhirong Yang, and Erkki Oja. Pairwise Clustering with t-PLSI. In Proceedings of the', '22nd International Conference on Artiﬁcial Neural Networks (ICANN), Lausanne, Switzerland, 2012.', 'Travel Grant Award.', '9. He Zhang, Mats Sjöberg, Jorma Laaksonen, and Erkki Oja. A Multimodal Information Collector for', 'Content-Based Image Retrieval System. ICONIP 2011, Shanghai, China, 2011. Oral presentation.', '10. He Zhang, Eimontas Augilius, Timo Honkela, Jorma Laaksonen et al. Analysing Emotional Semantics of', 'Abstract Art Using Low-Level Image Features. In Proceedings of the 10th International Conference on', 'Advances in Intelligent Data Analysis (IDA), Porto, Portugal, 2011. Oral presentation.', '11. He Zhang, Teemu Ruokolainen, Jorma Laaksonen, Christina Hochleitner, and Rudolf Traunmüller. Gaze', 'and Speech-Enhanced Content-Based Image Retrieval in Image Tagging. ICANN 2011, Espoo, Finland,', '2011. Poster presentation.', '12. Zhirong Yang, He Zhang, Zhijian Yuan, and Erkki Oja. Kullback-Leibler Divergence for Nonnegative Matrix', 'Factorisation. ICANN 2011, Espoo, Finland, 2011. Oral presentation.', 'Technical Reports', '13. He Zhang, Markus Koskela, and Jorma Laaksonen. Report on Forms of Enriched Relevance Feedback.', 'Technical Report TKK-ICS-R10, Helsinki University of Technology, Department of Information and', 'Computer Science. Presented at PinView meeting, University College London, 2008.', '14. He Zhang, Mats Sjöberg, and Jorma Laaksonen. Browser Extension for Pointer Track Feedback. PinView', 'Deliverables. Presented at PinView meeting, Leoben University, Austria, 2008.', '15. Christina Hochleitner, Rudolf Traunmuller, Teemu Ruokolainen, and He Zhang. Archiving with Supported', 'Tagging. PinView Deliverables. Presented in Celum Company, Austria, 2011.', 'CV: He Zhang, +358-50-5188888, klarke4001@gmail.com                  Page 3/3']\n",
            "company_names -- > None\n",
            "no_of_pages -- > 3\n",
            "total_experience -- > 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHYpvj76bsem"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}